<html>
<head>
<title>Getting started with Kafka in Docker and Java</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Docker和Java中的卡夫卡入门</h1>
<blockquote>原文：<a href="https://medium.com/javarevisited/getting-started-with-kafka-in-docker-and-java-2051ccef1ca7?source=collection_archive---------0-----------------------#2021-03-15">https://medium.com/javarevisited/getting-started-with-kafka-in-docker-and-java-2051ccef1ca7?source=collection_archive---------0-----------------------#2021-03-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="be05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如今，几乎每个企业都由数据驱动。每个应用程序都会创建数据，无论是日志消息、指标、用户活动、传出消息还是其他什么。数据的每个字节都有一些信息。我们接受信息，分析它，处理它，然后创造更多的输出。</p><h2 id="1517" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">卡夫卡是什么</h2><p id="48b7" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">Kafka是开源软件，它提供了一个存储、读取和分析数据流的框架。今天，任何来源产生的数据和日志都在被实时处理、再处理、分析和处理，这就是为什么<a class="ae kd" rel="noopener" href="/javarevisited/top-10-apache-kafka-online-training-courses-and-certifications-621f3c13b38c"> Apache Kafka </a>在数据流中发挥着重要作用。卡夫卡提供了三个主要功能。</p><ul class=""><li id="6b58" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc kj kk kl km bi translated">发布和订阅记录流，类似于消息队列或企业消息传递系统。</li><li id="b24a" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">按照记录生成的顺序有效地存储记录流。</li><li id="ea8b" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">实时处理记录流。</li></ul><p id="9541" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka主要用于构建实时流数据管道和适应数据流的应用程序。它结合了消息传递、存储和流处理，允许存储和分析历史和实时数据。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><a href="https://javarevisited.blogspot.com/2018/04/top-5-apache-kafka-course-to-learn.html"><div class="er es ks"><img src="../Images/d852652e952abcc759011ec8e9d844bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*fvvSv7il1CXYsXfloK1UZQ.png"/></div></a></figure><h2 id="3a5b" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">卡夫卡是如何工作的</h2><p id="2104" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">名为<strong class="ih hj">生产者</strong>的应用向Kafka节点<strong class="ih hj">代理</strong>发送消息<strong class="ih hj">记录</strong>，所述消息由名为<strong class="ih hj">消费者</strong>的其他应用处理。消息存储在一个<strong class="ih hj">主题</strong>中，消费者订阅该主题以接收新消息。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><a href="https://javarevisited.blogspot.com/2015/07/how-to-use-wait-notify-and-notifyall-in.html"><div class="er es la"><img src="../Images/10cec40c785546139887f73971d2f6d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*ysc4rtY1V3bLOLVkF9cUnA.png"/></div></a></figure><p id="3c4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是卡夫卡体系的主要部分:</p><p id="3fe2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">消息和批次:【Kafka内的数据单位称为消息。与消息最相似的是一行或一条记录。消息<br/>只是一个字节数组，因此其中包含的数据对于Kafka来说没有特定的格式或意义。一个消息可以有一个可选的<br/>位元数据，它被称为一个键。</strong></p><p id="a900" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了效率，消息被批量写入卡夫卡。批处理只是消息的集合，所有这些消息都被生成到同一个主题和分区。批处理越大，单位时间内可以处理的消息就越多，但是单个消息传播的时间就越长。</p><p id="d8e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模式:</strong>一致的数据格式在Kafka中很重要，因为它允许写和读消息分离。消息模式有许多选项，这取决于应用程序的个人需求，比如JSON或XML易于使用且易于阅读。</p><p id="5168" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生产者和消费者</strong> : Kafka客户端是系统的用户，有两种基本类型生产者和消费者。还有用于数据集成的高级客户端APIsKafka Connect API和用于流处理的Kafka Streams。高级客户端使用生产者和消费者作为构建块，并在其上提供更高级别的功能。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><a href="https://javarevisited.blogspot.com/2017/02/how-to-consume-json-from-restful-web-services-Spring-RESTTemplate-Example.html"><div class="er es lb"><img src="../Images/1d7e3897e3e86f739e4e8434e223b4f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ys-0fJ7hudlLycaTA55ZYA.png"/></div></a></figure><p id="ada9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生产者创造新的信息。在其他发布/订阅系统中，这些可以被称为发布者或作者。一般来说，会针对特定主题生成一条消息。</p><p id="9301" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">消费者阅读信息。在其他发布/订阅系统中，这些客户端可以被称为订阅者或读者。消费者订阅一个或多个主题，并按照消息产生的顺序阅读消息。消费者通过跟踪偏移量来跟踪它已经消费了哪些消息。</p><p id="938a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">主题和分区:</strong>卡夫卡的信息被分类成主题。与主题最相似的是数据库表或文件系统中的文件夹。生产者应用程序将数据写入主题，消费者应用程序从主题中读取数据。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><a href="https://javarevisited.blogspot.com/2020/05/top-16-jms-java-messaging-service-interview-questions-answers.html"><div class="er es lc"><img src="../Images/102c0450fa842fa889220c758963037a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UA5qZsIsfzecHdvFs6viyA.png"/></div></a></figure><p id="8c32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主题被分成几个部分。一个分区是一个日志。消息以仅附加的方式写入其中，并按照从开始到结束的顺序读取。一个主题可以有多个分区。分区允许通过跨多个代理将数据分成特定的主题来并行化主题。每个分区可以托管在不同的服务器上，这意味着单个主题可以跨多个服务器进行水平扩展，以提供远远超出单个服务器能力的性能。</p><p id="887c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">代理和集群</strong>:Kafka集群由一台或多台服务器组成，每台Kafka服务器称为一个代理。一个Kafka经纪人接收来自生产者的信息，并将它们存储在一个磁盘上。Kafka代理允许消费者通过主题、分区和偏移量获取消息。我们可以创建多种类型的集群，如下所示:</p><ul class=""><li id="c0ac" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc kj kk kl km bi translated">单一节点:单一代理集群</li><li id="9a63" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">单个节点:多个代理集群</li><li id="cff8" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">多个节点:多个代理集群</li></ul><p id="c143" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Zookeeper  : Kafka提供了默认的简单的Zookeeper配置文件，用于跟踪Kafka集群节点的状态，同时也跟踪Kafka主题、分区等。ZooKeeper有五个主要功能。具体来说，ZooKeeper用于控制器选举、集群成员资格、主题配置、访问控制列表和配额。</p><p id="1761" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1控制器选举。如果某个节点关闭，ZooKeeper会确保其他副本充当分区领导者的角色，取代正在关闭的节点中的分区领导者。</p><p id="741f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2集群成员。ZooKeeper保存了集群中所有正常运行的代理的列表。</p><p id="b15e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3话题配置。ZooKeeper维护所有主题的配置，包括现有主题的列表、每个主题的分区数量、副本的位置等。</p><p id="f339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4个访问控制列表(ACL)。ZooKeeper还维护所有主题的ACL。这包括谁或什么被允许读/写每个主题、消费者团体信息。</p><p id="af6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5个配额。ZooKeeper访问每个客户端允许读/写多少数据。</p><h2 id="ab8c" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">如何在Docker中启动Kafka服务器</h2><p id="7593" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated"><strong class="ih hj"> Apache </strong> Kafka是用<a class="ae kd" rel="noopener" href="/javarevisited/5-best-scala-and-functional-programming-books-to-learn-in-2021-97ec9e56f2bd"> <strong class="ih hj"> Scala </strong> </a>和<a class="ae kd" rel="noopener" href="/javarevisited/10-books-java-developers-should-read-in-2020-e6222f25cc72"> <strong class="ih hj"> Java </strong> </a> <strong class="ih hj">开发的使用流处理的软件总线的框架实现。</strong>在Windows上的<a class="ae kd" rel="noopener" href="/javarevisited/top-5-free-courses-to-learn-docker-for-beginners-best-of-lot-b2b1ad2b98ad"> Docker </a>中设置Kafka服务器的先决条件是java，一个正在运行的Docker实例，一个正在运行的Zookeeper实例。这是一个非常简单的例子。在本例中，我们将创建一个节点，即一个代理集群。</p><ol class=""><li id="6b59" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc ld kk kl km bi translated">在Windows上安装Docker桌面<a class="ae kd" href="https://hub.docker.com/editions/community/docker-ce-desktop-windows/" rel="noopener ugc nofollow" target="_blank">https://hub . Docker . com/editions/community/Docker-ce-Desktop-Windows/</a></li><li id="119d" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated">下载卡夫卡式<a class="ae kd" href="https://www.apache.org/dyn/closer.cgi?path=/kafka/2.7.0/kafka_2.12-2.7.0.tgz" rel="noopener ugc nofollow" target="_blank">https://www.apache.org/dyn/closer.cgi?path =/Kafka/2 . 7 . 0/Kafka _ 2.12-2 . 7 . 0 . tgz</a></li><li id="07de" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated">启动Docker引擎</li><li id="b63a" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated">创建一个名为“D:\docker”的目录</li><li id="7a11" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated">在上面的目录中创建一个docker-compose.yml文件</li></ol><figure class="kt ku kv kw fd kx"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="7364" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.启动动物园管理员和卡夫卡' docker-compose up -d '。它将下载Kafka和zookeeper的图像，并为它们创建和运行一个实例。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><a href="https://www.java67.com/2018/02/5-free-docker-courses-for-java-and-DevOps-engineers.html"><div class="er es lg"><img src="../Images/dcbfd25b399297f65a6412d58a1e712b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fb3VLKw9wtECgdwobtbQzg.png"/></div></a></figure><p id="82ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.现在卡夫卡和动物园管理员都在跑。现在，我们使用在步骤2中下载的Kafka创建一个主题。我们将解压它，进入目录/bin/window/并从那里打开cmd和创建主题的命令。</p><pre class="kt ku kv kw fd lh li lj lk aw ll bi"><span id="b28f" class="jd je hi li b fi lm ln l lo lp">kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic helloKafka</span><span id="fef9" class="jd je hi li b fi lq ln l lo lp">or</span><span id="0461" class="jd je hi li b fi lq ln l lo lp">kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic helloKafka</span></pre><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/3d19bc19cc16fd5b250caab911f85304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcpxHhB15AvEPnvistjU1g.png"/></div></div></figure><p id="6d3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8.主题“helloKafka”已经创建，现在我们需要创建一个生产者和消费者来访问这个主题。从位置&lt;\ Kafka _ 2.12–2 . 7 . 0 \ bin \ windows &gt;打开两个命令提示符，一个用于生产者，另一个用于消费者。在每个命令提示符下创建生产者和消费者。现在在生产者上键入一些消息。生产者将该消息发送到消费者订阅的主题“helloKafka ”,我们将在消费者的屏幕上看到该消息。</p><pre class="kt ku kv kw fd lh li lj lk aw ll bi"><span id="2ec3" class="jd je hi li b fi lm ln l lo lp">1)kafka-console-producer.bat --broker-list localhost:9092 --topic helloKafka</span><span id="cc62" class="jd je hi li b fi lq ln l lo lp">2)kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic helloKafka</span></pre><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lw"><img src="../Images/4d908049e5c5a1222c181af2c8fc3ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p2ky2HaxrrLfnvC7QLt2PQ.png"/></div></div></figure><h2 id="b785" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">Kafka Java API</h2><p id="1a6b" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">无论您是将Kafka用作队列、消息总线还是数据存储平台，您都将通过编写向Kafka写入数据的生产者、从Kafka读取数据的消费者或服务于这两种角色的应用程序来使用Kafka。Apache Kafka带有内置的客户端API，开发人员可以在开发与Kafka交互的应用程序时使用这些API。</p><p id="b989" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka有五个针对Java和Scala的核心API:</p><p id="7cae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka包括五个核心API:</p><ol class=""><li id="8be8" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc ld kk kl km bi translated"><strong class="ih hj"> Producer API </strong>允许应用程序向Kafka集群中的主题发送数据流。</li><li id="4998" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated"><strong class="ih hj"> ConsumerAPI </strong>允许应用程序从Kafka集群中的主题读取数据流。</li><li id="1ba8" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated"><strong class="ih hj">流API </strong>允许将数据流从输入主题转换成输出主题。</li><li id="dc6a" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated"><strong class="ih hj"> Connect API </strong>允许实现连接器，这些连接器不断地从某个源系统或应用程序拉入Kafka，或者从Kafka推入某个接收系统或应用程序。</li><li id="8b48" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated">管理API允许管理和检查主题、代理和其他Kafka对象。</li></ol><h2 id="cebc" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">如何打造卡夫卡制作人</h2><p id="cdc1" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">生产者是创建消息并将其发布给Kafka代理以供进一步消费的应用程序。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lx"><img src="../Images/d587afe6cdc36e4a412635ff8126d6a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*vMeRZKmkQva6_oEfZwNU-g.png"/></div></figure><p id="e28c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka Producer API用于创建定制的生产者应用程序，该应用程序生成消息并将其发送给代理。重要的接口和类如下。</p><p id="ed06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">接口生产者&lt; K，V &gt; : </strong>这是KafkaProducer <br/> <strong class="ih hj">类KafkaProducer &lt; K，V &gt; : </strong>这个类用于创建一个Kafka客户端，作为向Kafka集群发布记录的生产者。<br/><strong class="ih hj">Class Producer config:</strong>这用于为Kafka生产者<strong class="ih hj"> <br/>类ProducerRecord &lt; K，V &gt; : </strong>一个要发送给Kafka的键/值对进行<strong class="ih hj"> </strong>配置。这包括记录要发送到的主题名、可选的分区号以及可选的键和值。</p><ol class=""><li id="c39f" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc ld kk kl km bi translated">我们需要定义一些属性来与Kafka broker建立连接，并将这些属性传递给Kafka producer:</li></ol><pre class="kt ku kv kw fd lh li lj lk aw ll bi"><span id="06f4" class="jd je hi li b fi lm ln l lo lp">properties.put(ProducerConfig.<em class="ly">BOOTSTRAP_SERVERS_CONFIG</em>, "localhost:9092");<br/>properties.put(ProducerConfig.<em class="ly">KEY_SERIALIZER_CLASS_CONFIG</em>, StringSerializer.class);<br/>properties.put(ProducerConfig.<em class="ly">VALUE_SERIALIZER_CLASS_CONFIG</em>, StringSerializer.class);</span></pre><p id="f67b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生产者配置。BOOTSTRAP_SERVERS_CONFIG </strong>:这个属性告诉生产者需要连接到发布的代理。</p><p id="9936" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生产者配置。KEY_SERIALIZER_CLASS_CONFIG和ProducerConfig。VALUE _ SERIALIZER _ CLASS _ CONFIG:</strong>该属性告知在准备将消息从生产者传输到代理时需要使用的序列化程序类。</p><p id="d1c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.如下创建一个生产者实例，我们需要传递我们在上面定义的属性</p><pre class="kt ku kv kw fd lh li lj lk aw ll bi"><span id="fc75" class="jd je hi li b fi lm ln l lo lp">Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties);</span></pre><p id="edf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.需要创建一个将发送的<strong class="ih hj"> ProducerRecord </strong>的实例。</p><pre class="kt ku kv kw fd lh li lj lk aw ll bi"><span id="bbea" class="jd je hi li b fi lm ln l lo lp">ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;("TopicName", Key, Value);<br/><em class="ly">//produce the record<br/></em>producer.send(record);</span></pre><p id="30ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整的程序如下所示</p><figure class="kt ku kv kw fd kx"><div class="bz dy l di"><div class="le lf l"/></div></figure><h2 id="d0b4" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">如何创造卡夫卡式的消费者</h2><p id="56e3" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">消费者是使用Kafka生产者发布的消息并处理从中提取的数据的应用程序。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><a href="https://javarevisited.blogspot.com/2017/12/top-5-courses-to-learn-big-data-and.html#axzz6mKbga8XV"><div class="er es lz"><img src="../Images/fa2ae12a8d423a7f29894563227913b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*QBLrhr0ga1_XAN3HSPbItQ.png"/></div></a></figure><ol class=""><li id="f49d" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc ld kk kl km bi translated">我们需要定义一些属性来与Kafka代理建立连接，并将这些属性传递给Kafka消费者</li></ol><pre class="kt ku kv kw fd lh li lj lk aw ll bi"><span id="c406" class="jd je hi li b fi lm ln l lo lp">properties.put(ConsumerConfig.<em class="ly">BOOTSTRAP_SERVERS_CONFIG</em>, "localhost:9092");<br/>properties.put(ConsumerConfig.<em class="ly">GROUP_ID_CONFIG</em>, "my-first-consumer-group");<br/>properties.put(ConsumerConfig.<em class="ly">KEY_DESERIALIZER_CLASS_CONFIG</em>, StringDeserializer.class);<br/>properties.put(ConsumerConfig.<em class="ly">VALUE_DESERIALIZER_CLASS_CONFIG</em>, StringDeserializer.class);<br/>properties.put(ConsumerConfig.<em class="ly">AUTO_OFFSET_RESET_CONFIG</em>, "earliest");<br/>properties.put(ConsumerConfig.<em class="ly">ENABLE_AUTO_COMMIT_CONFIG</em>, false);</span></pre><p id="b93b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整的消费者应用程序看起来像</p><figure class="kt ku kv kw fd kx"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="9fad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我在这里所做的都是Kafka的基础知识，比如什么是Kafka，Kafka的重要组件，如何在窗口机器上创建单节点-单代理类型的集群。如何创造卡夫卡生产者和消费者？</p><p id="bd64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka在实时应用中有不同的用例。考虑一个网站的使用案例，其中需要跟踪连续的安全事件，如用户身份验证和访问安全资源的授权，并且需要针对任何安全漏洞实时做出决策。使用任何典型的面向批处理的数据处理系统(首先需要收集所有数据，然后进行分析/处理以揭示模式),将会为时过晚，无法确定web应用程序是否存在任何安全威胁。这些是实时数据处理的经典用例。</p><p id="324d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">物联网设备由各种传感器组成，这些传感器具有多个以高频率收集的数据点。一个简单的恒温器在与房间或汽车连接时，每分钟可以产生几个字节的数据。这些海量数据集用于存储、转换、处理、查询和分析。</p><p id="acf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka的另一个非常重要的用例是捕获用户点击流数据，如页面浏览、搜索等，作为实时发布-订阅提要。由于数据量非常大，这些数据被发布到中心主题，每个活动类型一个主题。这些主题可供包括实时处理和监控在内的各种应用的许多消费者订阅。</p><p id="f32d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这个基本介绍能帮助你了解和理解<a class="ae kd" rel="noopener" href="/javarevisited/top-5-big-data-frameworks-java-developers-can-learn-in-2021-9a3e20437c8c"> Apache Kafka </a>，它的基本原理，以及它的用例。在下一篇文章中，我将尝试解释如何使用其他Kafka API，如Kafka Stream API、Kafka Admin API，如何在将消息存储到Kafka集群之前拦截它，如何将Kafka与Storm集成。</p><p id="2477" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢这些信息，请仔细阅读，并通过评论和建议分享你的知识和理解。</p><h1 id="4ec8" class="ma je hi bd jf mb mc md jj me mf mg jn mh mi mj jq mk ml mm jt mn mo mp jw mq bi translated">资源</h1><ol class=""><li id="d0ca" class="ke kf hi ih b ii jy im jz iq mr iu ms iy mt jc ld kk kl km bi translated"><a class="ae kd" href="https://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">卡夫卡文献</a>:伟大、广泛、高质量的文献</li><li id="9f66" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc ld kk kl km bi translated">【https://www.confluent.io/learn/kafka-tutorial/ T4】</li></ol></div></div>    
</body>
</html>