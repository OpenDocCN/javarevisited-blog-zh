<html>
<head>
<title>Evaluating the Logistic Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评估Python中的逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/javarevisited/evaluating-the-logistic-regression-ae2decf42d61?source=collection_archive---------0-----------------------#2022-10-22">https://medium.com/javarevisited/evaluating-the-logistic-regression-ae2decf42d61?source=collection_archive---------0-----------------------#2022-10-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="99ee" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">所有你需要知道的关于逻辑回归的通用评估指标和Python中的代码示例。完整的代码是<a class="ae ix" href="https://github.com/vicky-playground/Sunnybrook/blob/main/HitPain.py" rel="noopener ugc nofollow" target="_blank">这里是</a>。</h2></div><p id="c8b4" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">逻辑回归是线性回归的一种变体。它为具有两种可能结果的<strong class="ja hj">分类问题</strong>的概率建模——即，成功/是/真/1的概率<em class="ju"> p </em>和失败/否/假/零的概率<em class="ju"> q (1-p) </em>。因此，输出符合如下pic所示的伯努利分布。因变量介于0和1之间。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es jv"><img src="../Images/d6f253543355518c4d2db5e4ac854c3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LIdcPBIIRCuAVmCb.PNG"/></div></div><p class="kh ki et er es kj kk bd b be z dx translated">来自维基百科的伯努利分布</p></figure><h1 id="53b8" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">逻辑回归的用例</h1><p id="0437" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">#1:欺诈检测</p><p id="3f49" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">#2:医疗诊断</p><p id="9d7f" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">#3:流失预测</p><h1 id="2075" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">逻辑回归的假设</h1><h2 id="865e" class="li km hi bd kn lj lk ll kr lm ln lo kv jh lp lq kx jl lr ls kz jp lt lu lb lv bi translated">#1:响应变量是二进制的</h2><p id="7980" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">如女性或男性，赢或输，成功或失败，恶性或良性。</p><h2 id="5be3" class="li km hi bd kn lj lk ll kr lm ln lo kv jh lp lq kx jl lr ls kz jp lt lu lb lv bi translated">#2:控制变量是独立的，不相关</h2><p id="e0e0" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">多重共线性将导致<strong class="ja hj">过度拟合</strong>，其中<strong class="ja hj">模型</strong>可能在已知的训练集上有良好的性能，但在未知的测试集上将会失败。在运行模型时，我们应该确保不存在多重共线性。也就是说，<strong class="ja hj">我们可以舍弃高度相关的变量，以免违背这个假设。</strong></p><p id="d807" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">要检查多重共线性，</strong>我们可以使用方差膨胀因子(<strong class="ja hj"> VIF </strong>)，它测量回归模型中预测变量之间的相关性。VIF值等于或小于5表示没有多重共线性；VIF表示高度相关。查看这个<a class="ae ix" href="https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/" rel="noopener ugc nofollow" target="_blank"> Python教程</a>来实现VIF价值观。</p><h2 id="92f5" class="li km hi bd kn lj lk ll kr lm ln lo kv jh lp lq kx jl lr ls kz jp lt lu lb lv bi translated">#3:没有极端异常值</h2><p id="3356" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">评估轮廓最常见的方法之一是计算库克距离。关于库克距离理论的深入解释可以在<a class="ae ix" href="https://ethanweed.github.io/pythonbook/05.04-regression.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。如果确实存在异常值，我们可以选择(1)消除它们，(2)用平均值或中值等值替换它们，或者(3)将它们保留在模型中，但在回归结果中报告它们。</p><h2 id="3a75" class="li km hi bd kn lj lk ll kr lm ln lo kv jh lp lq kx jl lr ls kz jp lt lu lb lv bi translated">#4:适度大样本量</h2><p id="266e" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">作为一个经验法则，我们应该有一个最小样本量<a class="ae ix" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6422534/#:~:text=In%20conclusion%2C%20for%20observational%20studies,parameters%20in%20the%20targeted%20population." rel="noopener ugc nofollow" target="_blank"><em class="ju">n</em>= 100+50<em class="ju">I</em></a>其中<em class="ju"> i </em>是指最终模型中自变量的数量。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es lw"><img src="../Images/b321518ef8cb6415558c5f4d1b9748c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:2/format:webp/1*PPwilZVSdw6W01pYtYiObw.png"/></div></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lx"><img src="../Images/a868cfbeef0346cdf76d1e07f993319f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oXz1z1EwHHSHjsDiEQs41Q.png"/></div></div><p class="kh ki et er es kj kk bd b be z dx translated">分类问题</p></figure><h1 id="6b51" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">培训和测试数据</h1><p id="95d3" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">在机器学习中，数据集分为两组:训练数据和测试数据。第一个子集称为<strong class="ja hj">训练数据— </strong>这是输入机器学习以训练(构建)模型的实际数据集。另一个子集被称为<strong class="ja hj">测试数据</strong> —它用以前看不到的数据测试模型的准确性。</p><h1 id="b859" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">分层抽样</h1><p id="3089" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated"><strong class="ja hj">当存在严重的类别不平衡时，进行标准的随机训练/测试分割是有风险的。</strong>这是因为您可能最终得到具有非常不同的类分布的训练集和测试集，因此您的测试集中可能几乎没有阳性结果。在这种情况下，通常选择<strong class="ja hj">分层抽样</strong>以<strong class="ja hj">确保样本数据与原始数据具有相同的各目标类百分比。</strong></p><p id="4f2a" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">代码示例:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ly"><img src="../Images/1c0fcae2526421e41b3773fa68fa7e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XbnVT04o7Xa3RHmUjhC-kw.png"/></div></div></figure><h1 id="ddbe" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">评估二元分类模型的通用性能指标</h1><p id="2bfb" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">这些性能指标包括<strong class="ja hj">混淆矩阵、准确度、精密度、灵敏度</strong> ( <strong class="ja hj">召回)、特异性和F1分数</strong>。Python文档可以参考<a class="ae ix" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" rel="noopener ugc nofollow" target="_blank">这里的</a>。一般来说，<strong class="ja hj">任何大于70% </strong>的精度都可以被认为是一个很好的模型性能。</p><p id="81ad" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> 1。</span> <strong class="ja hj">混淆矩阵</strong>:真/假和正/负预测率的表格汇总。它允许您计算各种<strong class="ja hj">性能指标。</strong></p><p id="82a2" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">代码示例:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mi"><img src="../Images/ae9d27f1996c65323a72bd1b68c6c02c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*inMXcA5gqQfsprx5WEi_ow.png"/></div></div></figure><p id="3292" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> 2。</span> <strong class="ja hj">准确度分数</strong>:测量所有预测结果中正确预测的比例。</p><pre class="jw jx jy jz fd mj mk ml mm aw mn bi"><span id="b659" class="li km hi mk b fi mo mp l mq mr"><strong class="mk hj">Accuracy = Number of correct predictions/Number of predictions</strong></span><span id="37b8" class="li km hi mk b fi ms mp l mq mr">Note: <br/>False Positives = <strong class="mk hj">Type I Error </strong><br/>False Negatives = <strong class="mk hj">Type II Error</strong></span></pre><p id="9a73" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">与不平衡数据集相反，它仅适用于分类中类的平均分布，因为错误预测的百分比可能较低，但同时，该模型在类的比例较低时表现不佳。因此，应用不平衡数据和需要正确预测少数类的情况是不实际的。这就是为什么在电子商务、信用卡欺诈检测和癌症预测等情况下，它可能会产生误导。</p><p id="009c" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">代码示例:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mt"><img src="../Images/8c106b61b6c0fc15503ea8be8591ed81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2spyO7E8o1ZEd5orRuYuw.png"/></div></div></figure><p id="afd6" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> 3。</span> <strong class="ja hj">精度</strong>:测量<strong class="ja hj">正面预测</strong>实际为正面的比例。</p><pre class="jw jx jy jz fd mj mk ml mm aw mn bi"><span id="dd23" class="li km hi mk b fi mo mp l mq mr"><strong class="mk hj">Precision = Number of true positives/(Number of true positives <em class="ju">+ </em>Number of <em class="ju">false positives</em>).</strong></span></pre><p id="6e4f" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">当类别非常不平衡，并且在没有任何假阳性的情况下识别所有阳性示例非常经济高效时，精度分数对于<strong class="ja hj">成功预测尤其有用。</strong></p><p id="7f8b" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">使用回忆分数的真实场景👉在信用卡欺诈检测问题中，分类模型使用精度分数来监控模型性能，以降低误报率。</p><p id="3030" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">代码示例:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mu"><img src="../Images/69a44d0760f3bd9b44285d6bb139c2d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A0_cAD7n1ZSxjKVl2-SyHQ.png"/></div></div></figure><p id="e932" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> 4。</span> <strong class="ja hj">灵敏度</strong> ( <strong class="ja hj">召回)</strong>:表示模型在<strong class="ja hj">实际阳性</strong>中正确预测阳性的能力。回忆分数越高，机器学习模型在<strong class="ja hj">识别阳性越好。</strong></p><pre class="jw jx jy jz fd mj mk ml mm aw mn bi"><span id="7e53" class="li km hi mk b fi mo mp l mq mr"><strong class="mk hj">Recall = Number of true positives / (Number of true positives + Number of <em class="ju">false negatives</em>).</strong></span></pre><p id="061d" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">使用回忆分数的真实场景👉在医学诊断中，任何不能解释假阴性的事情都是严重的，因此在这种情况下，<strong class="ja hj"> recall </strong> score是比precision更好的衡量标准。另一方面，垃圾邮件过滤器不太关心假阴性，所以这里的<strong class="ja hj">精度</strong>更好。</p><p id="d629" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">代码示例:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mv"><img src="../Images/9f42506846ef7f16f7dcc2d93aefd167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNsX3-HYysA7HmwzKdw1EA.png"/></div></div></figure><p id="7a29" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> 5。</span> <strong class="ja hj">特异性</strong>:代表模型从<strong class="ja hj">实际否定</strong>中正确预测否定的能力。特异性得分越高，机器学习模型在<strong class="ja hj">识别否定时就越好。</strong></p><p id="ffcd" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">代码示例:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mw"><img src="../Images/eb94afbb78bb2f396894f58815dcb167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GFToOEAmAU0cN5cTx1NjuA.png"/></div></div></figure><blockquote class="mx my mz"><p id="c7bb" class="iy iz ju ja b jb jc ij jd je jf im jg na ji jj jk nb jm jn jo nc jq jr js jt hb bi translated">它经常被比作灵敏度，因为<strong class="ja hj"> </strong>灵敏度和特异性成反比:<strong class="ja hj">灵敏度越高，特异性越低，反之亦然。换句话说，不可能同时优化这两个指标。一般来说，<strong class="ja hj">当你想最大化正确阳性的预测时，灵敏度比特异性更重要。</strong>另一方面，<strong class="ja hj">当你想最小化错误否定的预测时，特异性比敏感性更重要。</strong></strong></p><p id="83a4" class="iy iz ju ja b jb jc ij jd je jf im jg na ji jj jk nb jm jn jo nc jq jr js jt hb bi translated">需要注意的一点是<a class="ae ix" href="https://analyticsindiamag.com/beginners-guide-to-understanding-roc-curve-how-to-find-the-perfect-probability-threshold/" rel="noopener ugc nofollow" target="_blank"> <strong class="ja hj">阈值化</strong> </a>可以同时影响灵敏度和特异性。这意味着改变阴性预测和阳性预测的分界点会影响灵敏度和特异性。</p><p id="c116" class="iy iz ju ja b jb jc ij jd je jf im jg na ji jj jk nb jm jn jo nc jq jr js jt hb bi translated">代码示例:</p></blockquote><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mu"><img src="../Images/0ae32e5d8f9cec156ed15563bd2e04e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-auOB3M4JMrLbhucbKcixw.png"/></div></div><p class="kh ki et er es kj kk bd b be z dx translated">降低正面预测的阈值</p></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es nd"><img src="../Images/8eec35efda09a8a1a5149888800058d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jn7B1ymz3bP-XwOBGv-5rQ.png"/></div></div></figure><p id="500e" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> 6。</span><strong class="ja hj">F-score(F1-score)</strong>:<strong class="ja hj">结合模型的精度和召回率</strong>，是精度和召回率的<strong class="ja hj">调和平均值</strong>。当数据不平衡时经常使用<strong class="ja hj">。</strong></p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ne"><img src="../Images/9924a3054faef0e947da44fa6a33d341.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrDWO4tftcZPe4vF0CdWPQ.png"/></div></div></figure><h1 id="56fb" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">用ROC确定最佳概率临界值(阈值)</h1><p id="8b66" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">接收器操作特性(<a class="ae ix" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank"> ROC曲线</a>)通常用于获得最佳概率阈值，以提高机器学习模型的预测能力。</p><p id="0cf9" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">有两种方法可以获得正类的最佳阈值:</p><ol class=""><li id="4369" class="nf ng hi ja b jb jc je jf jh nh jl ni jp nj jt nk nl nm nn bi translated"><a class="ae ix" href="https://en.wikipedia.org/wiki/Youden%27s_J_statistic" rel="noopener ugc nofollow" target="_blank">尤登氏J统计</a></li><li id="7e2c" class="nf ng hi ja b jb no je np jh nq jl nr jp ns jt nk nl nm nn bi translated"><a class="ae ix" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">欧几里德距离</a></li></ol><p id="d221" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我将使用Youden的J统计量来获得代码示例中的最佳概率阈值:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es nt"><img src="../Images/eaa89225e1ea4ea4ded014dbe44a6599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoZxHY114eaF1yHzNyny_w.png"/></div></div><p class="kh ki et er es kj kk bd b be z dx translated">尤登J统计量</p></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es nu"><img src="../Images/38ffad5dcd6bc7358f2d77a5837ba113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s48WVvbZTbZIvDCZH_-5nA.png"/></div></div></figure><h1 id="6800" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">结论</h1><p id="3c5e" class="pw-post-body-paragraph iy iz hi ja b jb ld ij jd je le im jg jh lf jj jk jl lg jn jo jp lh jr js jt hb bi translated">哪个指标应该优化取决于<strong class="ja hj">业务目标。</strong>例如，在医疗诊断或欺诈交易检测器的情况下，灵敏度(召回)分数更重要，因为假阴性的成本比假阳性更不可接受。然而，当涉及到客户流失或YouTube推荐时，精确度或特异性更重要，因为假阴性比假阳性更容易接受。</p><p id="cbbc" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">希望有所帮助。感谢阅读！</p></div></div>    
</body>
</html>