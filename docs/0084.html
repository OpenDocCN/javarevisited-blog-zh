<html>
<head>
<title>ML 101 (Part 2): Linear Regression, Gradient Descend &amp; Cost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML 101(第二部分):线性回归、梯度下降和成本</h1>
<blockquote>原文：<a href="https://medium.com/javarevisited/ml-101-part-2-linear-regression-gradient-descend-cost-58950ae85301?source=collection_archive---------0-----------------------#2019-06-22">https://medium.com/javarevisited/ml-101-part-2-linear-regression-gradient-descend-cost-58950ae85301?source=collection_archive---------0-----------------------#2019-06-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/12fb44e058a8a47fb742e536d110b9cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRx_L9C7jcThkbVqEINuxg.png"/></div></div></figure><p id="5094" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">又见面了。</p><p id="d66c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">今天的帖子是我的机器学习101帖子系列的第2部分。在阅读这篇文章之前，如果你对机器学习一无所知，你可以参考<a class="ae jo" rel="noopener" href="/@phantomgrin/ml-101-part-1-basics-of-machine-learning-1734836696c1">第一部分:机器学习基础</a>。</p><p id="efcf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为今天的主题做个介绍，我将回忆一下我在以前的帖子中提到的一些事情，这些事情与线性回归有关。</p><p id="e323" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用机器学习，我们可以回答5种类型的问题。所以机器学习中的所有算法都是为了回答其中一个问题而形成的。以下是这些问题及其相关算法:</p><ol class=""><li id="87f5" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">多少或多少？→ <strong class="is hj"> <em class="jy">回归算法</em> </strong></li><li id="99e8" class="jp jq hi is b it jz ix ka jb kb jf kc jj kd jn ju jv jw jx bi translated">a还是B？→ <strong class="is hj"> <em class="jy">分类算法</em> </strong></li><li id="1167" class="jp jq hi is b it jz ix ka jb kb jf kc jj kd jn ju jv jw jx bi translated">这是怎么组织的？→ <strong class="is hj"> <em class="jy">聚类算法</em> </strong></li><li id="8d44" class="jp jq hi is b it jz ix ka jb kb jf kc jj kd jn ju jv jw jx bi translated">很奇怪吗？→ <strong class="is hj"> <em class="jy">异常检测算法</em> </strong></li><li id="cfa3" class="jp jq hi is b it jz ix ka jb kb jf kc jj kd jn ju jv jw jx bi translated">下一步该怎么办？→ <strong class="is hj"> <em class="jy">强化学习算法</em> </strong></li></ol><p id="46ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大多数时候，基于问题1和2的算法是在监督学习下，而问题3和4是在非监督学习下。(在<a class="ae jo" rel="noopener" href="/@phantomgrin/ml-101-part-1-basics-of-machine-learning-1734836696c1"> ML 101:第一部分</a>中查看更多关于监督、非监督和强化学习的信息)</p><p id="403a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们来看看线性回归。顾名思义，线性回归属于回归算法。它回答了'<strong class="is hj"> <em class="jy">多少</em> </strong>或'<strong class="is hj"> <em class="jy">多少'</em> </strong>的问题。</p><p id="580a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了讨论这个话题，让我们举一个例子:我们要测量运动的小时数和燃烧的卡路里数之间的关系。(假设卡路里的单位是千焦)。因为小时是独立变量，所以它是X轴，而卡路里是Y轴(因变量)。</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div class="er es ke"><img src="../Images/3e54d95443b2359de3775bba7411210c.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*KT3Ed3LpY-zf0ZqY4gMnKg.png"/></div><p class="kj kk et er es kl km bd b be z dx translated">具有x和y坐标的表格</p></figure><p id="9ac0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果我们将它绘制成散点图，我们将得到如下结果:</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/e0d483a9bc9a72e2ae8ca226ee5d2cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*TNRTE5nhcVPORIf-Xpa-iw.png"/></div><p class="kj kk et er es kl km bd b be z dx translated">散点图中上表的点</p></figure><p id="5705" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，蓝色菱形表示上表中提到的实际值。</p><p id="cb43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那么，如果有人告诉你他们锻炼的小时数，并问你大概消耗了多少卡路里呢？这就是我们需要一种机制来预测随时间变化的卡路里。这些机制之一是线性回归。</p><p id="0204" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在线性回归中，我们所做的是找到最佳拟合线，这样，我们可以使用该线预测新<code class="du ko kp kq kr b"><strong class="is hj">X</strong></code>的值。</p><p id="7dc8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从学校级别的数学中，我们知道一条线的方程:y=mx+c，对于线性回归也是一样的。我们做的是，系统地找出这个“m”和“c”。由此，我们确定最佳拟合线或y^ (y hat)</p><blockquote class="ks"><p id="524b" class="kt ku hi bd kv kw kx ky kz la lb jn dx translated">y^ = mx + c</p></blockquote><p id="8891" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">让我们来看看如何为上面的数据集计算最佳拟合线。</p><p id="764e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在<code class="du ko kp kq kr b"><strong class="is hj">y^ = mx + c</strong></code>中找到<code class="du ko kp kq kr b"><strong class="is hj">m</strong></code>的数学方程式是:</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="877a" class="ll lm hi kr b fi ln lo l lp lq">m = ∑ (x-x’).(y-y’) / ∑(x-x’)²</span></pre><p id="61d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们将扩展上表来计算如下等式:</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/fd1bd4c1061728ff5687f0d697b9895b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*SUdlkyBi9BOzyQykclO45g.png"/></div><p class="kj kk et er es kl km bd b be z dx translated">方程式的计算</p></figure><p id="ffc4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在使用上表:</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="e835" class="ll lm hi kr b fi ln lo l lp lq">m = 6 / 10 = 0.6</span></pre><p id="2a43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">太好了！现在我们必须找到c，我们该怎么做呢？</p><p id="73b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在求上述方程的c时，有一个非常重要的概念我们需要知道。也就是说，最佳拟合线应该穿过点(A)，在该点处，线<code class="du ko kp kq kr b"><strong class="is hj">x = x’</strong></code>(x的平均值)和<code class="du ko kp kq kr b"><strong class="is hj">y = y’</strong></code><strong class="is hj"/>(y的平均值)相互交叉。查看下图，了解更多信息:</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/3cee1aa68873af4fa696a3fa7ca6db74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WpMRQnfIgVi42BckdEgfeQ.png"/></div></div><p class="kj kk et er es kl km bd b be z dx translated">最佳拟合线，x=x '线和y=y '线在A点相交</p></figure><p id="0d33" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如上所述，点A是所有3条线上的点；<code class="du ko kp kq kr b"><strong class="is hj">y^= mx+c</strong></code>、<code class="du ko kp kq kr b"><strong class="is hj">y=y’</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">x=x’</strong></code>。因此，我们可以使用该逻辑计算c(我们已经知道m):</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="17a4" class="ll lm hi kr b fi ln lo l lp lq">y' = mx'+c</span><span id="3285" class="ll lm hi kr b fi lt lo l lp lq">c = y' - mx' = 4 - (0.6 * 3)<br/>c = 4 - 1.8<br/>c = 2.2</span></pre><p id="3fd6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，在该数据集中，最佳拟合线为:</p><blockquote class="ks"><p id="0d09" class="kt ku hi bd kv kw kx ky kz la lb jn dx translated">y^ = 0.6x + 2.2</p></blockquote><p id="158b" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">太好了！！我们找到了数据集的最佳拟合线！很简单，不是吗？但是在实际场景中，数据集比我举的例子要复杂得多。因此，该模型不能容易地计算最佳拟合线。这就是为什么线性回归以迭代的方式发生。那是什么意思？</p><p id="8ea4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当模型获得数据集时，在第一次迭代中，他计算随机最佳拟合线的<code class="du ko kp kq kr b"><strong class="is hj">m</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">c</strong></code>。然后，他使用实际值和预测值查看最佳拟合线的“<strong class="is hj"> <em class="jy">误差</em> </strong>”或“<strong class="is hj"> <em class="jy">成本</em> </strong>”。然后在下一次迭代中，他再次调整最佳拟合线的<code class="du ko kp kq kr b"><strong class="is hj">m</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">c</strong></code>，以最小化该误差。这个循环会持续我们在模型中提到的迭代次数。因此，我们需要对模型进行微调，使其停在最佳拟合直线方程上。</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/327882919eebb91cfae07b4afa9d6bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*iiXz6nV4IQFhJ8uAk2yTnw.gif"/></div></div><p class="kj kk et er es kl km bd b be z dx translated">m和c的值在每次迭代中更新以获得最优解(来源:<a class="ae jo" href="https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931" rel="noopener" target="_blank">走向数据科学，2019 </a>)</p></figure><p id="5f47" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们更详细地了解一下这是如何发生的:</p><p id="7572" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我之前提到的，首先，我们从随机的m和c值(通常都为零)开始，并计算这些值的y^。下一步，我们计算这一行的“<strong class="is hj"> <em class="jy">成本</em> </strong>或“<strong class="is hj"> <em class="jy">误差</em> </strong>”。有许多函数可以用于这种计算。这些被称为<strong class="is hj"> <em class="jy">成本函数</em> </strong>。一个这样的函数是“<strong class="is hj"><em class="jy"/></strong>”或“<strong class="is hj"> <em class="jy">均方误差</em> </strong>”。</p><p id="98a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">MSE取实际值和预测值之间的差值，并对其求平方，以避免抵消负值和正值。然后将所有这些相加，除以数据点的数量。</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="78a6" class="ll lm hi kr b fi ln lo l lp lq">MSE = (1/n) ∑ (y-y^)²</span></pre><p id="cb3d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">MSE将是我在这篇文章后面使用的成本函数。但是，让我告诉你还有哪些可用的成本函数:</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="5a65" class="ll lm hi kr b fi ln lo l lp lq">SEE = Standard Error of Estimate<br/>SEE = √ ∑(y-y^)² /(n-2)</span><span id="fae1" class="ll lm hi kr b fi lt lo l lp lq">MAE = Mean Absolute Error<br/>MAE = (1/n) ∑ |y-y^|</span><span id="214b" class="ll lm hi kr b fi lt lo l lp lq">RAE = Relative Absolute Error<br/>RAE = ∑ |y-y^| / ∑ |y-y'|</span><span id="cf4c" class="ll lm hi kr b fi lt lo l lp lq">RSE = Relative Squared Error<br/>RSE = ∑ (y-y^)² / ∑ (y-y')²</span><span id="dcee" class="ll lm hi kr b fi lt lo l lp lq">CoD = Coefficient of Determination (R²)<br/>CoD = 1 - (∑(y-y^)² / ∑(y-y')²) <br/>CoD = 1 - RSE</span></pre><p id="1159" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以现在我们选择了<code class="du ko kp kq kr b"><strong class="is hj">MSE</strong></code>作为我们的成本函数。我们接下来要做的是使用成本函数来计算估计的m和c的成本。然后我们需要对<code class="du ko kp kq kr b"><strong class="is hj">m</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">c</strong></code>做一个小的调整，这样我们可以进一步最小化MSE，<strong class="is hj"> <em class="jy">(如果可能的话)</em> </strong>。</p><p id="72ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你没奇怪我为什么说:“如果可能”吗？那是因为<code class="du ko kp kq kr b"><strong class="is hj">m,</strong></code> <code class="du ko kp kq kr b"><strong class="is hj">c</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">MSE</strong></code>之间的图形总是弯曲的，如下图:</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/3eae9a238c499b94098054dbbfee3ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uY7sBPjLyytpojJJDqiKyg.png"/></div></div><p class="kj kk et er es kl km bd b be z dx translated">MSE、m和b之间的图(在我们的例子中是c)[来源:<a class="ae jo" href="https://www.youtube.com/watch?v=vsWrXfO3wWw" rel="noopener ugc nofollow" target="_blank"> YouTube，2019 </a> ]</p></figure><p id="96bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果我们一次取两个平面并绘制此图，它将给出如下两个曲线图:</p><div class="kf kg kh ki fd ab cb"><figure class="lw ij lx ly lz ma mb paragraph-image"><img src="../Images/0e2a2d18a3a5d9a35902d4b11ee2aee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*MWM3TJsK2B7bUn-Jc74YPg.png"/></figure><figure class="lw ij mc ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/0667ba2cc10d81b490d27589b92ad905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*cZ4D3yv9vL3fSeYMLB1KsQ.png"/></div><p class="kj kk et er es kl km bd b be z dx md di me mf translated">MSE和m以及MSE和b之间的图(在我们的例子中是c)[来源:<a class="ae jo" href="https://www.youtube.com/watch?v=vsWrXfO3wWw" rel="noopener ugc nofollow" target="_blank"> YouTube，2019 </a> ]</p></figure></div><p id="19a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以我们需要正确地找到图表的最低点。如果我们采取固定大小的步骤，很有可能会超过最低点。相反，我们需要根据我们在图表中的当前位置采取措施。</p><div class="kf kg kh ki fd ab cb"><figure class="lw ij mg ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/f35a1c671d4e3e8855b82febc9ffd25d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*uTPo5GOWCx30oPq9lSlUnA.png"/></div></figure><figure class="lw ij mh ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/8de7f236632b47e8f775c33404aa8ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*Xgk6XI4kEcSmDaEAxqB1CA.png"/></div><p class="kj kk et er es kl km bd b be z dx mi di mj mf translated">如何通过固定大小的步骤移动将无法达到全局最小值，而采取成比例的步骤将在达到全局最小值方面起作用。【来源:<a class="ae jo" href="https://www.youtube.com/watch?v=vsWrXfO3wWw" rel="noopener ugc nofollow" target="_blank"> YouTube，2019 </a></p></figure></div><p id="f973" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以我想到的下一个问题是，我们如何确定该走多大的一步，向哪个方向走。这就是梯度下降开始起作用的时候。</p><p id="ec01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">想象你是下图中被蒙住眼睛的登山者:</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/5573b0e40f17a3a10e8afd3fa6edb2a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*LsTRB6CZL6DzD1_kotcdFg.png"/></div></div></figure><p id="7362" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你的脚会辨别山坡的坡度，是陡峭还是平坦。根据这一点，你会知道你的步伐应该有多大。</p><p id="a943" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一方面，从斜坡的方向，你可以猜出你下一步需要走的方向。</p><p id="1644" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，在山脚附近，你会感觉山很陡，你会向上迈出巨大的一步以快速到达山顶。同样，在接近顶部时，你会觉得斜坡几乎是平的，你会采取较小的步骤以避免过度。</p><p id="ab63" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">像登山者一样，梯度下降在调整<code class="du ko kp kq kr b"><strong class="is hj">m</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">c</strong></code>时也要考虑两件事。也就是往哪个方向走，步子要迈多大。</p><p id="c95e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我们需要测量在特定时刻<code class="du ko kp kq kr b">MSE-m-c curve graph</code>中一点的斜率。那么怎么才能走坡呢？这时，你的高级数学知识就很重要了😋</p><p id="5c72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">两点(或一条线)之间的斜率计算如下:→</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="9631" class="ll lm hi kr b fi ln lo l lp lq">change in y / change in x<br/>= (y1-y2) / (x1-x2) <br/>    <br/>      → <strong class="kr hj"><em class="jy">dy / dx</em></strong></span></pre><p id="193f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那一分呢？我们如何计算一个点的斜率？因为两个点完全相同，所以<code class="du ko kp kq kr b">dy</code>和<code class="du ko kp kq kr b">dx</code>都将为零，不是吗？</p><p id="dcbe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这种情况下，我们通过考虑y和x的微小变化(接近零)来计算斜率。这由<code class="du ko kp kq kr b"><strong class="is hj">△y / △x</strong></code>表示。我们用导数的知识来计算这个<code class="du ko kp kq kr b"><strong class="is hj">△y</strong></code>和<code class="du ko kp kq kr b"><strong class="is hj">△x</strong></code>。</p><p id="79c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们看看我们的MSE方程:</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="81a9" class="ll lm hi kr b fi ln lo l lp lq">MSE = (1/n) ∑ (y-y^)²</span></pre><p id="4e3c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以用下面的m和c写这个方程，用方程<code class="du ko kp kq kr b">mx+c</code>代替<code class="du ko kp kq kr b">y^</code>。</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="dc9a" class="ll lm hi kr b fi ln lo l lp lq">MSE = (1/n) ∑ (y-(mx+c))²</span></pre><p id="ffc8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如你所见，我们需要找到MSE和两个变量之间的关系。那就是<code class="du ko kp kq kr b">m</code>和<code class="du ko kp kq kr b">c</code>。在这种情况下，我们不能简单地计算整个方程的导数。相反，我们必须计算出“<strong class="is hj"> <em class="jy">【偏导数】</em></strong>”(∂).偏导数是在假设方程中所有其他变量都为零的情况下计算的导数，除了我们考虑的变量。这意味着，如果我们想计算上述方程对<code class="du ko kp kq kr b">m</code>的偏导数，我们假设<code class="du ko kp kq kr b">c</code>为零，并计算方程的导数。</p><p id="1cc2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，MSE方程关于<code class="du ko kp kq kr b">m</code>和<code class="du ko kp kq kr b">c</code>的偏导数如下:</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="cdf6" class="ll lm hi kr b fi ln lo l lp lq">∂/∂m = <!-- -->(2/n) ∑ -x(y-(mx+c))<br/>∂/∂c = <!-- -->(2/n) ∑ -(y-(mx+c))</span></pre><p id="6371" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们知道该往哪个方向走，才能达到全局最小值。台阶的大小呢？这就是“<strong class="is hj"> <em class="jy">学习率</em></strong>”(LR)的概念发挥作用的地方。学习率是一个固定值，表示我们的校正或学习应该有多大。LR和偏导数一起给出了我们需要对<code class="du ko kp kq kr b">m</code>或<code class="du ko kp kq kr b">c</code>进行的总调整，以便在下一个<code class="du ko kp kq kr b">m</code>或<code class="du ko kp kq kr b">c</code>进行推导。</p><blockquote class="ml mm mn"><p id="4634" class="iq ir jy is b it iu iv iw ix iy iz ja mo jc jd je mp jg jh ji mq jk jl jm jn hb bi translated">尽管LR是一个固定值，但当与偏导数相乘时，它会根据点在图上的位置给出一个比例值。</p></blockquote><p id="00fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">好吧！现在让我们用一个简单的代码来实现它。(你可以用Jupyter笔记本或者Colab笔记本试试这个)</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/56c72a4fea216dc8803e693caec9433e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90lOIn59tofmUbnjxspwdw.png"/></div></div><p class="kj kk et er es kl km bd b be z dx translated">实现梯度下降算法的代码(<a class="ae jo" href="https://gist.github.com/PhantomGrin/a6ace45009bd893f93ec1ff1e9154f7b" rel="noopener ugc nofollow" target="_blank">代码</a>)</p></figure><p id="c683" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出:</p><pre class="kf kg kh ki fd lh kr li lj aw lk bi"><span id="0188" class="ll lm hi kr b fi ln lo l lp lq">epoch : 0, m : 0.6000000000000176, c : 2.1999999999999362, MSE : 0.47999999999999987 <br/>epoch : 1, m : 0.6000000000000176, c : 2.1999999999999362, MSE : 0.47999999999999987 <br/>epoch : 2, m : 0.6000000000000176, c : 2.1999999999999362, MSE : 0.47999999999999987<br/>...<br/>...<br/>...<br/>epoch : 1497, m : 0.6000000000000176, c : 2.1999999999999362, MSE : 0.47999999999999987 <br/>epoch : 1498, m : 0.6000000000000176, c : 2.1999999999999362, MSE : 0.47999999999999987 <br/>epoch : 1499, m : 0.6000000000000176, c : 2.1999999999999362, MSE : 0.47999999999999987</span></pre><p id="80cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以看到计算出的<code class="du ko kp kq kr b">m</code>和<code class="du ko kp kq kr b">c</code>与我们手动计算的<code class="du ko kp kq kr b">m</code>和<code class="du ko kp kq kr b">c</code>几乎吻合。</p><blockquote class="ml mm mn"><p id="a4b2" class="iq ir jy is b it iu iv iw ix iy iz ja mo jc jd je mp jg jh ji mq jk jl jm jn hb bi translated">请注意，LR和epochs是要微调的值。最初将纪元设置为一个较低的值，如20，将LR设置为3个小数点(例如0.001)。运行代码，看看MSE是增加还是减少。如果增加，LR变小，反之亦然，如果减少。找到合适的LR后，增加历元。</p></blockquote><p id="c9ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">找到了。我们涵盖了我们需要知道的关于线性回归的一切，包括成本函数和梯度下降！我们还检查了代码是如何完成的。然而，这些模型有着悠久的历史，并且它们有自己的使用各种python库的实现。最佳实践是使用它们而不是手动编码，除非您想尝试一下。</p><p id="a840" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望我增加了你的知识。😇让我们在下一个帖子里见面吧。同时，如果你有任何疑问或地方，请随时发表评论。</p><p id="b1d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">快乐学习！❤</p><blockquote class="ml mm mn"><p id="addc" class="iq ir jy is b it iu iv iw ix iy iz ja mo jc jd je mp jg jh ji mq jk jl jm jn hb bi translated">PS:如果你想查看如何用scikit-learn实现线性回归，可以查看我下面的要点。👇</p></blockquote><p id="792d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://gist.github.com/PhantomGrin/10dc8c7c9a796c91cac386ee779f017e" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/phantom grin/10 DC 8 c 7 c 9 a 796 c 91 CAC 386 ee 779 f 017 e</a></p></div></div>    
</body>
</html>